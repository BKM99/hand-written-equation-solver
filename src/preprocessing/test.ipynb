{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52c6078d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import base64\n",
    "from PIL import Image, ImageOps\n",
    "from io import BytesIO\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "587d64ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_h = 32\n",
    "img_w = 32\n",
    "channels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "536447e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_input_img(img):\n",
    "#     img = cv2.imread(img,cv2.IMREAD_GRAYSCALE)\n",
    "    if img is not None:\n",
    "        img=~img\n",
    "        ret,thresh=cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "        ctrs,h=cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnt=sorted(ctrs, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "        w=int(img_w)\n",
    "        h=int(img_h)\n",
    "        train_data=[]\n",
    "        rects=[]\n",
    "        for c in cnt :\n",
    "            x,y,w,h= cv2.boundingRect(c)\n",
    "            rect=[x,y,w,h]\n",
    "            rects.append(rect)\n",
    "        bool_rect=[]\n",
    "        for r in rects:\n",
    "            l=[]\n",
    "            for rec in rects:\n",
    "                flag=0\n",
    "                if rec!=r:\n",
    "                    if r[0]<(rec[0]+rec[2]+10) and rec[0]<(r[0]+r[2]+10) and r[1]<(rec[1]+rec[3]+10) and rec[1]<(r[1]+r[3]+10):\n",
    "                        flag=1\n",
    "                    l.append(flag)\n",
    "                if rec==r:\n",
    "                    l.append(0)\n",
    "            bool_rect.append(l)\n",
    "        dump_rect=[]\n",
    "        for i in range(0,len(cnt)):\n",
    "            for j in range(0,len(cnt)):\n",
    "                if bool_rect[i][j]==1:\n",
    "                    area1=rects[i][2]*rects[i][3]\n",
    "                    area2=rects[j][2]*rects[j][3]\n",
    "                    if(area1==min(area1,area2)):\n",
    "                        dump_rect.append(rects[i])\n",
    "        final_rect=[i for i in rects if i not in dump_rect]\n",
    "        for r in final_rect:\n",
    "            x=r[0]\n",
    "            y=r[1]\n",
    "            w=r[2]\n",
    "            h=r[3]\n",
    "            im_crop =thresh[y:y+h+10,x:x+w+10]\n",
    "            im_resize = cv2.resize(im_crop,(img_h,img_w))\n",
    "            im_resize=np.reshape(im_resize,(img_h,img_w,channels))\n",
    "            train_data.append(im_resize)\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82a072c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(img_arr):\n",
    "    s=''\n",
    "    for i in range(len(img_arr)):\n",
    "        img_arr[i]=np.array(img_arr[i])\n",
    "        img_arr[i]=img_arr[i].reshape(1,img_h,img_w,channels)\n",
    "        result=model.predict_classes(img_arr[i])\n",
    "        print(int(result))\n",
    "        if(result[0]==12):\n",
    "            s=s+'-'\n",
    "        if(result[0]==11):\n",
    "            s=s+'+'\n",
    "        if(result[0]==10):\n",
    "            s=s+'*'\n",
    "        if(result[0]==0):\n",
    "            s=s+'0'\n",
    "        if(result[0]==1):\n",
    "            s=s+'1'\n",
    "        if(result[0]==2):\n",
    "            s=s+'2'\n",
    "        if(result[0]==3):\n",
    "            s=s+'3'\n",
    "        if(result[0]==4):\n",
    "            s=s+'4'\n",
    "        if(result[0]==5):\n",
    "            s=s+'5'\n",
    "        if(result[0]==6):\n",
    "            s=s+'6'\n",
    "        if(result[0]==7):\n",
    "            s=s+'7'\n",
    "        if(result[0]==8):\n",
    "            s=s+'8'\n",
    "        if(result[0]==9):\n",
    "            s=s+'9'\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46c83c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    }
   ],
   "source": [
    "model = load_model('model/model32x32-1639256834')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d49994",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
